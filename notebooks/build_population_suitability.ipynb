{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6a42da-2bd0-4553-84a7-23968b051bb6",
   "metadata": {},
   "source": [
    "# Building population suitablity layers for GRIDCERF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98f900-a29c-476b-97a9-52d6c105e2a4",
   "metadata": {},
   "source": [
    "## 1. Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f8fea-93e6-4b84-83c4-5868f236fee4",
   "metadata": {},
   "source": [
    "### 1.1 Download GRIDCERF\n",
    "\n",
    "Download the GRIDCERF package if you have not yet done so from here:  https://doi.org/10.5281/zenodo.6601789.  Please extract GRIDCERF inside the `data` directory of this repository as the paths in this notebook are set to that expectation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea70c1e0-ea87-4494-9996-b7367c2707e8",
   "metadata": {},
   "source": [
    "## 2. Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e013bc-a9df-4a20-80ed-cb1e93ca6f44",
   "metadata": {},
   "source": [
    "### 2.1 Install GDAL\n",
    "\n",
    "This application requires GDAL to be installed.  We will call GDAL directly from your command prompt or terminal, so please ensure that you can do so before running the following cells.  More information on how to install GDAL can be found here:  https://gdal.org/download.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f2e8a6-be36-4b51-a242-3d66c4328e20",
   "metadata": {},
   "source": [
    "### 2.2 Install Python third-party dependencies\n",
    "\n",
    "The following Python packages can be installed directly from the following kernel if they are not already in your kernel's environment.  If you are using conda, please use conda specific install protocol.\n",
    "\n",
    "**NOTE**: Executing the following cell will install these Python packages over your existing versions!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e93b9d-11d3-4a3a-9e01-309d384fec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Iv numpy>=1.23.1\n",
    "!pip install -Iv pandas>=1.4.3\n",
    "!pip install -Iv rasterio>=1.3.4\n",
    "!pip install -Iv geopandas>=0.12.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221e84b-9735-4916-993a-b9e33afabf39",
   "metadata": {},
   "source": [
    "### 2.3 Import necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51656ba6-795a-4b2f-9af4-3cf5c3596c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "from numba import jit, njit\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from scipy.ndimage import convolve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a95257-0e31-4ef6-80ae-7761a886556f",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474e928-d112-4a51-8702-53078a0b31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parent directory path to where this notebook is currently stored\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# data directory in repository\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "# GRIDCERF data directory from downloaded archive\n",
    "gridcerf_dir = os.path.join(data_dir, \"gridcerf\")\n",
    "\n",
    "# GRIDCERF reference data directory\n",
    "reference_dir = os.path.join(gridcerf_dir, \"reference\")\n",
    "\n",
    "# GRIDCERF common data directory\n",
    "common_dir = os.path.join(gridcerf_dir, \"common\")\n",
    "\n",
    "# GRIDCERF technology_specific data directory\n",
    "technology_specific_dir = os.path.join(gridcerf_dir, \"technology_specific\")\n",
    "\n",
    "# GRIDCERF compiled final suitability data directory\n",
    "compiled_dir = os.path.join(gridcerf_dir, \"compiled\")\n",
    "\n",
    "# population rasters\n",
    "population_dir = \"/Users/d3y010/projects/population/data/population_conus_total_ssp2_2020_1km.asc\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6235254f-ffbd-4827-bcdc-7fb8fa5a1269",
   "metadata": {},
   "source": [
    "## 4. Generate population rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29294e2d-18fe-4645-abfd-833480012e76",
   "metadata": {},
   "source": [
    "### 4.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab3c2b4f-a3df-4de7-9b21-8b8384459de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_ascii(arr, r_ascii, xll=-180, yll=-90, cellsize=0.25, nodata=-999):\n",
    "    \"\"\"\n",
    "    Convert a numpy array to an ASCII raster.\n",
    "    :@param arr:            2D array\n",
    "    :@param r_ascii:        Full path to outfile with extension\n",
    "    :@param xll:            Longitude coordinate for lower left corner\n",
    "    :@param yll:            Latitude coordinate for lower left corner\n",
    "    :@param cellsize:       Cell size in geographic degrees\n",
    "    :@param nodata:         Value representing NODATA\n",
    "    \"\"\"\n",
    "\n",
    "    # get number of rows and columns of array\n",
    "    nrows = arr.shape[0]\n",
    "    ncols = arr.shape[1]\n",
    "\n",
    "    # create ASCII raster file\n",
    "    with open(r_ascii, 'w') as rast:\n",
    "\n",
    "        # write header\n",
    "        rast.write('ncols {}\\n'.format(ncols))\n",
    "        rast.write('nrows {}\\n'.format(nrows))\n",
    "        rast.write('xllcorner {}\\n'.format(xll))\n",
    "        rast.write('yllcorner {}\\n'.format(yll))\n",
    "        rast.write('cellsize {}\\n'.format(cellsize))\n",
    "        rast.write('nodata_value {}\\n'.format(nodata))\n",
    "\n",
    "        # write array\n",
    "        np.savetxt(rast, arr, fmt='%.15g')\n",
    "        \n",
    "\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def create_buffer(radius):  #radius given in #cells\n",
    "    \n",
    "    b = []\n",
    "    for i in range(radius+1):\n",
    "        \n",
    "        for j in range(radius+1):\n",
    "            \n",
    "            if math.sqrt(i**2 + j**2) <= radius:\n",
    "                \n",
    "                if i==0 and j==0:\n",
    "                    b.extend([(i,j)])\n",
    "                elif i==0:\n",
    "                    b.extend([(i,j),(i,-j)])\n",
    "                elif j==0:\n",
    "                    b.extend([(i,j),(-i,j)])\n",
    "                else:\n",
    "                    b.extend([(i,j),(-i,j),(i,-j),(-i,-j)])\n",
    "                    \n",
    "    return b\n",
    "\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def check_unsuitable_cells(unsuitable_cells, unsuitable_shapes, threshold):\n",
    "    while len(unsuitable_cells) > 0:\n",
    "        start_cell = unsuitable_cells.pop()\n",
    "        to_check = [start_cell]\n",
    "        this_shape = [start_cell]\n",
    "\n",
    "        while len(to_check) > 0:\n",
    "            cell = to_check.pop()\n",
    "            for i, j in [(0, -1), (0, 1), (-1, 0), (1, 0)]:\n",
    "                if (cell[0]+i, cell[1]+j) in unsuitable_cells:\n",
    "                    to_check.append((cell[0]+i, cell[1]+j))\n",
    "                    this_shape.append((cell[0]+i, cell[1]+j))\n",
    "                    unsuitable_cells.remove((cell[0]+i, cell[1]+j))\n",
    "\n",
    "        if len(this_shape) > threshold:\n",
    "            unsuitable_shapes.extend(this_shape)\n",
    "            \n",
    "    return unsuitable_cells, unsuitable_shapes\n",
    "\n",
    "\n",
    "def main(input_raster, out_dir, scenario, year=2100, buffer_km=40):\n",
    " \n",
    "    buffer_relative = create_buffer(buffer_km)        #25 mile (40 km) buffer\n",
    "    buffer_relative.reverse()                   #Look at biggest buffers first\n",
    "\n",
    "    unbuffered_file = os.path.join(out_dir, f\"cerf_densely_populated_{scenario}_{year}.asc\")\n",
    "    buffered_file = os.path.join(out_dir, f\"cerf_densely_populated_{scenario}_{year}_buff25mi.asc\")\n",
    "    nuclear_file = os.path.join(out_dir, f\"cerf_densely_populated_{scenario}_{year}_nuclear.asc\")\n",
    "\n",
    "    headers = []\n",
    "    in_raster_data = []\n",
    "    unsuitable_cells = []\n",
    "    unsuitable_shapes = []\n",
    "    buffered_shapes = []\n",
    "\n",
    "    print('Loading input raster\\n')\n",
    "    inf = open(input_raster,'r')\n",
    "    currentline = inf.readline()\n",
    "\n",
    "    nodata_val = '-999'\n",
    "\n",
    "    while currentline.split()[0] != nodata_val:\n",
    "        headers.append(currentline)\n",
    "        currentline = inf.readline()\n",
    "    while currentline:\n",
    "        in_raster_data.append([int(x) for x in currentline.split()])\n",
    "        currentline = inf.readline()\n",
    "    inf.close()\n",
    "\n",
    "    print( 'Producing unbuffered file\\n')\n",
    "    #produce unbuffered file\n",
    "    f = open(unbuffered_file,'w')\n",
    "    for line in headers:\n",
    "        f.write(line)\n",
    "        \n",
    "    for rowi in range(len(in_raster_data)):\n",
    "        for columni in range(len(in_raster_data[rowi])):\n",
    "            cell = in_raster_data[rowi][columni]\n",
    "            threshold = 772\n",
    "                \n",
    "            if cell > threshold:\n",
    "                f.write('1 ')\n",
    "                unsuitable_cells.append((rowi,columni))\n",
    "                \n",
    "            elif cell == -9999:\n",
    "                f.write('1 ')\n",
    "            else:\n",
    "                f.write('0 ')\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "    print( 'Producing buffered file\\n')\n",
    "    print( '...identifying unsuitable blocks')\n",
    "            \n",
    "    threshold = 64.75\n",
    "\n",
    "    while len(unsuitable_cells) > 0:\n",
    "        start_cell = unsuitable_cells.pop()\n",
    "        to_check = [start_cell]\n",
    "        this_shape = [start_cell]\n",
    "        \n",
    "        while len(to_check) > 0:\n",
    "            cell = to_check.pop()\n",
    "            if (cell[0],cell[1]-1) in unsuitable_cells:\n",
    "                to_check.append((cell[0],cell[1]-1))\n",
    "                this_shape.append((cell[0],cell[1]-1))\n",
    "                unsuitable_cells.remove((cell[0],cell[1]-1))\n",
    "            if (cell[0],cell[1]+1) in unsuitable_cells:\n",
    "                to_check.append((cell[0],cell[1]+1))\n",
    "                this_shape.append((cell[0],cell[1]+1))\n",
    "                unsuitable_cells.remove((cell[0],cell[1]+1))\n",
    "            if (cell[0]-1,cell[1]) in unsuitable_cells:\n",
    "                to_check.append((cell[0]-1,cell[1]))\n",
    "                this_shape.append((cell[0]-1,cell[1]))\n",
    "                unsuitable_cells.remove((cell[0]-1,cell[1]))\n",
    "            if (cell[0]+1,cell[1]) in unsuitable_cells:\n",
    "                to_check.append((cell[0]+1,cell[1]))\n",
    "                this_shape.append((cell[0]+1,cell[1]))\n",
    "                unsuitable_cells.remove((cell[0]+1,cell[1]))\n",
    "                \n",
    "        if len(this_shape) > threshold:\n",
    "            unsuitable_shapes.extend(this_shape)\n",
    "            \n",
    "    unsuitable_cells = this_shape = None     #free up memory\n",
    "\n",
    "    print( '...buffering')\n",
    "    buffered_shapes = set(buffered_shapes)\n",
    "    \n",
    "    for cell in unsuitable_shapes:\n",
    "        \n",
    "        for offset in buffer_relative:\n",
    "            buffered_shapes.add((cell[0]+offset[0], cell[1]+offset[1]))\n",
    "\n",
    "\n",
    "    print( '...printing result\\n')\n",
    "    with open(buffered_file,'w') as f:\n",
    "        for line in headers:\n",
    "            f.write(line)\n",
    "        for rowi in range(len(in_raster_data)):\n",
    "            for columni in range(len(in_raster_data[rowi])):\n",
    "                if (rowi,columni) in buffered_shapes:\n",
    "                    f.write('1 ')\n",
    "                elif in_raster_data[rowi][columni] == -9999:\n",
    "                    f.write('1 ')\n",
    "                else:\n",
    "                    f.write('0 ')\n",
    "            f.write('\\n')\n",
    "    \n",
    "\n",
    "    print('Producing nuclear file...')\n",
    "    buffer_relative=[]\n",
    "    for i in range(40+1):\n",
    "        buffer_relative.append(create_buffer(i))\n",
    "    cell_area = 1\n",
    "        \n",
    "    nrows = len(in_raster_data)\n",
    "    ncolumns = len(in_raster_data[0])\n",
    "    \n",
    "    f = open(nuclear_file,'w')\n",
    "    for line in headers:\n",
    "        f.write(line)\n",
    "    for rowi in range(nrows):\n",
    "\n",
    "        for columni in range(ncolumns):\n",
    "            suitable = True\n",
    "            break_flag = False\n",
    "            for radius in buffer_relative:\n",
    "                if not break_flag:\n",
    "                    totalpop = 0\n",
    "                    totalarea = 0\n",
    "\n",
    "                    for offset in radius:\n",
    "                        new_row = rowi + offset[0]\n",
    "                        new_column = columni + offset[1]\n",
    "                        if new_row >= 0 and new_row < nrows and new_column >= 0 and new_column < ncolumns and \\\n",
    "                           in_raster_data[new_row][new_column] != -9999:\n",
    "                            totalpop += in_raster_data[new_row][new_column]\n",
    "                            totalarea += cell_area\n",
    "\n",
    "                    if totalarea != 0:\n",
    "                        density = float(totalpop)/totalarea\n",
    "                        if density > 193:\n",
    "                            suitable = False\n",
    "                            break_flag = True\n",
    "                        elif density < 30:\n",
    "                            break_flag = True\n",
    "                    else:\n",
    "                        suitable = False\n",
    "                        break_flag = True\n",
    "            if suitable:\n",
    "                f.write('0 ')\n",
    "            else:\n",
    "                f.write('1 ')\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af62f3e-1682-49be-a58d-364654dfe732",
   "metadata": {},
   "source": [
    "### 4.2 This code generates the population files on a year by year basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6411e6fc-38cc-412f-9e38-6559a4fa1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "outcome = main(f_asc, \n",
    "                 out_dir=os.path.dirname(f_asc), \n",
    "                 scenario=\"ssp2\", \n",
    "                 year=2020)\n",
    "\n",
    "\n",
    "nuclear_file, headers, nrows, ncolumns, buffer_relative, in_raster_data = outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4b15b-3b2a-44aa-b771-80d304d7acc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73bce0-4be2-42cb-b303-571bcad019b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30577da4-651b-4abb-a6ea-284a361e81a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227821e3-4556-44cd-b3cb-0f1a33ebdecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8bdde4-60f6-44a1-90bf-e8a7ffe0f62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df53d856-6328-4577-9cc4-565f7d713963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb00a03-64af-4476-bacc-3865b4535979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a893db-1a88-4fee-ab12-d34bc196f187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4ee33-991f-4437-a821-0fa05f09635b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa85539-cdcc-4420-9ffb-cfecce9e34be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6764be-a29d-46cf-aeff-1043e6685d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba8a61-5d3d-437c-894a-76836fbf4ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db68f5a5-9124-4044-8f57-9f2688dc3cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "population_per_kilometer = 772\n",
    "buffer_in_km = 40\n",
    "\n",
    "# raster for gridded 1 kilometer population over the contiguous united states\n",
    "population_raster_file = \"/Users/d3y010/projects/population/data/population_conus_total_ssp2_2020_1km.tif\"\n",
    "\n",
    "# output raster files\n",
    "dense_population_raster_file = \"/Users/d3y010/projects/population/data/dense_population_area.tif\"\n",
    "buffered_dense_population_raster_file = \"/Users/d3y010/projects/population/data/buffered_dense_population_area.tif\"\n",
    "\n",
    "\n",
    "# read in raster file to a numpy array\n",
    "with rasterio.open(population_raster_file) as src:\n",
    "    metadata = src.meta.copy()\n",
    "    population_array = src.read(1)\n",
    "\n",
    "# determine population density \n",
    "dense_population_area_array = np.where(population_array >= population_per_kilometer, 1, 0).astype(np.float32)\n",
    "\n",
    "# write dense population raster file\n",
    "with rasterio.open(dense_population_raster_file, 'w', **metadata) as dst:\n",
    "    dst.write(dense_population_area_array, 1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57c0c345-8b74-43fe-beee-a89231b50182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer each gridcell in the dense population area array by the kernel size\n",
    "from skimage.morphology import dilation, square, disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6d2cec0-c20e-48d8-bf00-9d4149ad1049",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "convolve() got an unexpected keyword argument 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:10\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: convolve() got an unexpected keyword argument 'function'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "kernel_size = int(buffer_in_km / 2)\n",
    "# selem = square(kernel_size)\n",
    "selem = disk(kernel_size)\n",
    "\n",
    "# buffered_dense_population_array = dilation(dense_population_area_array, selem)\n",
    "\n",
    "def count_zeros(arr):\n",
    "    return np.sum(arr == 0)\n",
    "\n",
    "conv_result = convolve(dense_population_area_array, selem, mode='constant', cval=0, origin=0, function=count_zeros)\n",
    "\n",
    "dense_population_area_array[conv_result >= 60] = 0\n",
    "dense_population_area_array[conv_result < 60] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6af18e28-838a-4d54-9648-0d11dfb8b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_dense_population_array = np.where(buffered_dense_population_array >= 1, 1, 0)\n",
    "\n",
    "# write dense population raster file\n",
    "with rasterio.open(buffered_dense_population_raster_file, 'w', **metadata) as dst:\n",
    "    dst.write(buffered_dense_population_array, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2244b1a-ec78-4f9b-8e8f-0b9b4cb08f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e696381-571e-4247-820a-97eee99942af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d7821-c535-4259-bbd4-69d9ef7e2895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16027ac5-ce4f-42ff-a834-5a1462a38a14",
   "metadata": {},
   "source": [
    "## New code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6d0ea2-c3d3-4cd1-ac9b-05ab95dc41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_per_kilometer = 772\n",
    "buffer_in_km = 40\n",
    "\n",
    "# raster for gridded 1 kilometer population over the contiguous united states\n",
    "population_raster_file = \"/Users/d3y010/projects/population/data/population_conus_total_ssp2_2020_1km.tif\"\n",
    "\n",
    "# output raster files\n",
    "dense_population_raster_file = \"/Users/d3y010/projects/population/data/dense_population_area.tif\"\n",
    "buffered_dense_population_raster_file = \"/Users/d3y010/projects/population/data/buffered_dense_population_area.tif\"\n",
    "\n",
    "\n",
    "# read in raster file to a numpy array\n",
    "with rasterio.open(population_raster_file) as src:\n",
    "    metadata = src.meta.copy()\n",
    "    population_array = src.read(1)\n",
    "\n",
    "# determine population density \n",
    "dense_population_area_array = np.where(population_array >= population_per_kilometer, 1, 0).astype(np.float32)\n",
    "\n",
    "# write dense population raster file\n",
    "with rasterio.open(dense_population_raster_file, 'w', **metadata) as dst:\n",
    "    dst.write(dense_population_area_array, 1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ba69cc-ef18-4c44-9ab2-5d58c01cb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "\n",
    "kernel_size = int(buffer_in_km / 2)\n",
    "kernel = np.ones((kernel_size, kernel_size), dtype=int)\n",
    "\n",
    "convolved_array = convolve(dense_population_area_array, kernel, mode='constant', cval=0)\n",
    "\n",
    "# Set all elements in the array equal to 1 where the kernel equals 1\n",
    "buffered_dense_population_array = np.where(convolved_array >= 1, 1, 0)\n",
    "\n",
    "# write dense population raster file\n",
    "with rasterio.open(buffered_dense_population_raster_file, 'w', **metadata) as dst:\n",
    "    dst.write(buffered_dense_population_array, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39a76e-8f6d-4bf8-9c1d-2d9a1f187b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d457ba4-81fb-4469-bccf-b7d3ebea4337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e1b50-df1d-443e-9c44-f53d2826c74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f808d-3a25-4d1e-9f7f-db420d063a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a99ab13-b3bd-424a-b808-0d0ac30ea7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a48976d-c3a6-4ec6-bf6b-02cfedd8a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"/Users/d3y010/projects/population/data/population_conus_total_ssp2_2020_1km.tif\"\n",
    "f_asc = \"/Users/d3y010/projects/population/data/population_conus_total_ssp2_2020_1km.asc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648adccd-b05a-4e29-b2cc-0b8cd13d82a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb43db-caae-4bdd-8c16-24a70e93256e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff93705-b88f-4e53-ada4-25dcbf60d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_ascii(arr, r_ascii, xll=-180, yll=-90, cellsize=0.25, nodata=-999):\n",
    "    \"\"\"\n",
    "    Convert a numpy array to an ASCII raster.\n",
    "    :@param arr:            2D array\n",
    "    :@param r_ascii:        Full path to outfile with extension\n",
    "    :@param xll:            Longitude coordinate for lower left corner\n",
    "    :@param yll:            Latitude coordinate for lower left corner\n",
    "    :@param cellsize:       Cell size in geographic degrees\n",
    "    :@param nodata:         Value representing NODATA\n",
    "    \"\"\"\n",
    "\n",
    "    # get number of rows and columns of array\n",
    "    nrows = arr.shape[0]\n",
    "    ncols = arr.shape[1]\n",
    "\n",
    "    # create ASCII raster file\n",
    "    with open(r_ascii, 'w') as rast:\n",
    "\n",
    "        # write header\n",
    "        rast.write('ncols {}\\n'.format(ncols))\n",
    "        rast.write('nrows {}\\n'.format(nrows))\n",
    "        rast.write('xllcorner {}\\n'.format(xll))\n",
    "        rast.write('yllcorner {}\\n'.format(yll))\n",
    "        rast.write('cellsize {}\\n'.format(cellsize))\n",
    "        rast.write('nodata_value {}\\n'.format(nodata))\n",
    "\n",
    "        # write array\n",
    "        np.savetxt(rast, arr, fmt='%.15g')\n",
    "        \n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def create_buffer(radius):  #radius given in #cells\n",
    "    \n",
    "    b = []\n",
    "    for i in range(radius+1):\n",
    "        \n",
    "        for j in range(radius+1):\n",
    "            \n",
    "            if math.sqrt(i**2 + j**2) <= radius:\n",
    "                \n",
    "                if i==0 and j==0:\n",
    "                    b.extend([(i,j)])\n",
    "                elif i==0:\n",
    "                    b.extend([(i,j),(i,-j)])\n",
    "                elif j==0:\n",
    "                    b.extend([(i,j),(-i,j)])\n",
    "                else:\n",
    "                    b.extend([(i,j),(-i,j),(i,-j),(-i,-j)])\n",
    "                    \n",
    "    return b\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def check_unsuitable_cells(unsuitable_cells, unsuitable_shapes, threshold):\n",
    "    while len(unsuitable_cells) > 0:\n",
    "        start_cell = unsuitable_cells.pop()\n",
    "        to_check = [start_cell]\n",
    "        this_shape = [start_cell]\n",
    "\n",
    "        while len(to_check) > 0:\n",
    "            cell = to_check.pop()\n",
    "            for i, j in [(0, -1), (0, 1), (-1, 0), (1, 0)]:\n",
    "                if (cell[0]+i, cell[1]+j) in unsuitable_cells:\n",
    "                    to_check.append((cell[0]+i, cell[1]+j))\n",
    "                    this_shape.append((cell[0]+i, cell[1]+j))\n",
    "                    unsuitable_cells.remove((cell[0]+i, cell[1]+j))\n",
    "\n",
    "        if len(this_shape) > threshold:\n",
    "            unsuitable_shapes.extend(this_shape)\n",
    "            \n",
    "    return unsuitable_cells, unsuitable_shapes\n",
    "\n",
    "\n",
    "def main(input_raster, out_dir, scenario, year=2100, buffer_km=40):\n",
    " \n",
    "    buffer_relative = create_buffer(buffer_km)        #25 mile (40 km) buffer\n",
    "    buffer_relative.reverse()                   #Look at biggest buffers first\n",
    "\n",
    "    unbuffered_file = os.path.join(out_dir, f\"cerf_densely_populated_{scenario}_{year}.asc\")\n",
    "    buffered_file = os.path.join(out_dir, f\"cerf_densely_populated_{scenario}_{year}_buff25mi.asc\")\n",
    "    nuclear_file = os.path.join(out_dir, f\"cerf_densely_populated_{scenario}_{year}_nuclear.asc\")\n",
    "\n",
    "    headers = []\n",
    "    in_raster_data = []\n",
    "    unsuitable_cells = []\n",
    "    unsuitable_shapes = []\n",
    "    buffered_shapes = []\n",
    "\n",
    "    print('Loading input raster\\n')\n",
    "    inf = open(input_raster,'r')\n",
    "    currentline = inf.readline()\n",
    "\n",
    "    nodata_val = '-999'\n",
    "\n",
    "    while currentline.split()[0] != nodata_val:\n",
    "        headers.append(currentline)\n",
    "        currentline = inf.readline()\n",
    "    while currentline:\n",
    "        in_raster_data.append([int(x) for x in currentline.split()])\n",
    "        currentline = inf.readline()\n",
    "    inf.close()\n",
    "\n",
    "    print( 'Producing unbuffered file\\n')\n",
    "    #produce unbuffered file\n",
    "    f = open(unbuffered_file,'w')\n",
    "    for line in headers:\n",
    "        f.write(line)\n",
    "        \n",
    "    for rowi in range(len(in_raster_data)):\n",
    "        for columni in range(len(in_raster_data[rowi])):\n",
    "            cell = in_raster_data[rowi][columni]\n",
    "            threshold = 772\n",
    "                \n",
    "            if cell > threshold:\n",
    "                f.write('1 ')\n",
    "                unsuitable_cells.append((rowi,columni))\n",
    "                \n",
    "            elif cell == -9999:\n",
    "                f.write('1 ')\n",
    "            else:\n",
    "                f.write('0 ')\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "    print( 'Producing buffered file\\n')\n",
    "    print( '...identifying unsuitable blocks')\n",
    "\n",
    "    threshold = 64.75\n",
    "\n",
    "    while len(unsuitable_cells) > 0:\n",
    "        start_cell = unsuitable_cells.pop()\n",
    "        to_check = [start_cell]\n",
    "        this_shape = [start_cell]\n",
    "        \n",
    "        while len(to_check) > 0:\n",
    "            cell = to_check.pop()\n",
    "            if (cell[0],cell[1]-1) in unsuitable_cells:\n",
    "                to_check.append((cell[0],cell[1]-1))\n",
    "                this_shape.append((cell[0],cell[1]-1))\n",
    "                unsuitable_cells.remove((cell[0],cell[1]-1))\n",
    "            if (cell[0],cell[1]+1) in unsuitable_cells:\n",
    "                to_check.append((cell[0],cell[1]+1))\n",
    "                this_shape.append((cell[0],cell[1]+1))\n",
    "                unsuitable_cells.remove((cell[0],cell[1]+1))\n",
    "            if (cell[0]-1,cell[1]) in unsuitable_cells:\n",
    "                to_check.append((cell[0]-1,cell[1]))\n",
    "                this_shape.append((cell[0]-1,cell[1]))\n",
    "                unsuitable_cells.remove((cell[0]-1,cell[1]))\n",
    "            if (cell[0]+1,cell[1]) in unsuitable_cells:\n",
    "                to_check.append((cell[0]+1,cell[1]))\n",
    "                this_shape.append((cell[0]+1,cell[1]))\n",
    "                unsuitable_cells.remove((cell[0]+1,cell[1]))\n",
    "                \n",
    "        if len(this_shape) > threshold:\n",
    "            unsuitable_shapes.extend(this_shape)\n",
    "            \n",
    "    unsuitable_cells = this_shape = None     #free up memory\n",
    "\n",
    "    print( '...buffering')\n",
    "    buffered_shapes = set(buffered_shapes)\n",
    "    \n",
    "    for cell in unsuitable_shapes:\n",
    "        \n",
    "        for offset in buffer_relative:\n",
    "            buffered_shapes.add((cell[0]+offset[0], cell[1]+offset[1]))\n",
    "\n",
    "\n",
    "#     print( '...printing result\\n')\n",
    "#     with open(buffered_file,'w') as f:\n",
    "#         for line in headers:\n",
    "#             f.write(line)\n",
    "#         for rowi in range(len(in_raster_data)):\n",
    "#             for columni in range(len(in_raster_data[rowi])):\n",
    "#                 if (rowi,columni) in buffered_shapes:\n",
    "#                     f.write('1 ')\n",
    "#                 elif in_raster_data[rowi][columni] == -9999:\n",
    "#                     f.write('1 ')\n",
    "#                 else:\n",
    "#                     f.write('0 ')\n",
    "#             f.write('\\n')\n",
    "    \n",
    "\n",
    "#     print('Producing nuclear file...')\n",
    "#     buffer_relative=[]\n",
    "#     for i in range(40+1):\n",
    "#         buffer_relative.append(create_buffer(i))\n",
    "#     cell_area = 1\n",
    "        \n",
    "#     nrows = len(in_raster_data)\n",
    "#     ncolumns = len(in_raster_data[0])\n",
    "    \n",
    "#     f = open(nuclear_file,'w')\n",
    "#     for line in headers:\n",
    "#         f.write(line)\n",
    "#     for rowi in range(nrows):\n",
    "\n",
    "#         for columni in range(ncolumns):\n",
    "#             suitable = True\n",
    "#             break_flag = False\n",
    "#             for radius in buffer_relative:\n",
    "#                 if not break_flag:\n",
    "#                     totalpop = 0\n",
    "#                     totalarea = 0\n",
    "\n",
    "#                     for offset in radius:\n",
    "#                         new_row = rowi + offset[0]\n",
    "#                         new_column = columni + offset[1]\n",
    "#                         if new_row >= 0 and new_row < nrows and new_column >= 0 and new_column < ncolumns and \\\n",
    "#                            in_raster_data[new_row][new_column] != -9999:\n",
    "#                             totalpop += in_raster_data[new_row][new_column]\n",
    "#                             totalarea += cell_area\n",
    "\n",
    "#                     if totalarea != 0:\n",
    "#                         density = float(totalpop)/totalarea\n",
    "#                         if density > 193:\n",
    "#                             suitable = False\n",
    "#                             break_flag = True\n",
    "#                         elif density < 30:\n",
    "#                             break_flag = True\n",
    "#                     else:\n",
    "#                         suitable = False\n",
    "#                         break_flag = True\n",
    "#             if suitable:\n",
    "#                 f.write('0 ')\n",
    "#             else:\n",
    "#                 f.write('1 ')\n",
    "#         f.write('\\n')\n",
    "#     f.close()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3314742-2dc3-4bda-9b4b-1fcffbee2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_ascii(arr, r_ascii, xll=-180, yll=-90, cellsize=0.25, nodata=-999):\n",
    "    \"\"\"\n",
    "    Convert a numpy array to an ASCII raster.\n",
    "    :@param arr:            2D array\n",
    "    :@param r_ascii:        Full path to outfile with extension\n",
    "    :@param xll:            Longitude coordinate for lower left corner\n",
    "    :@param yll:            Latitude coordinate for lower left corner\n",
    "    :@param cellsize:       Cell size in geographic degrees\n",
    "    :@param nodata:         Value representing NODATA\n",
    "    \"\"\"\n",
    "\n",
    "    # get number of rows and columns of array\n",
    "    nrows = arr.shape[0]\n",
    "    ncols = arr.shape[1]\n",
    "\n",
    "    # create ASCII raster file\n",
    "    with open(r_ascii, 'w') as rast:\n",
    "\n",
    "        # write header\n",
    "        rast.write('ncols {}\\n'.format(ncols))\n",
    "        rast.write('nrows {}\\n'.format(nrows))\n",
    "        rast.write('xllcorner {}\\n'.format(xll))\n",
    "        rast.write('yllcorner {}\\n'.format(yll))\n",
    "        rast.write('cellsize {}\\n'.format(cellsize))\n",
    "        rast.write('nodata_value {}\\n'.format(nodata))\n",
    "\n",
    "        # write array\n",
    "        np.savetxt(rast, arr, fmt='%.15g')\n",
    "        \n",
    "\n",
    "\n",
    "def create_buffer(radius):  #radius given in #cells\n",
    "    \n",
    "    b = []\n",
    "    for i in range(radius+1):\n",
    "        \n",
    "        for j in range(radius+1):\n",
    "            \n",
    "            if math.sqrt(i**2 + j**2) <= radius:\n",
    "                \n",
    "                if i==0 and j==0:\n",
    "                    b.extend([(i,j)])\n",
    "                elif i==0:\n",
    "                    b.extend([(i,j),(i,-j)])\n",
    "                elif j==0:\n",
    "                    b.extend([(i,j),(-i,j)])\n",
    "                else:\n",
    "                    b.extend([(i,j),(-i,j),(i,-j),(-i,-j)])\n",
    "                    \n",
    "    return b\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def check_suitability(rowi, columni, in_raster_data, buffer_relative, nrows, ncolumns):\n",
    "    suitable = True\n",
    "    break_flag = False\n",
    "    for radius in buffer_relative:\n",
    "        if not break_flag:\n",
    "            totalpop = 0\n",
    "            totalarea = 0\n",
    "\n",
    "            for offset in radius:\n",
    "                new_row = rowi + offset[0]\n",
    "                new_column = columni + offset[1]\n",
    "                if new_row >= 0 and new_row < nrows and new_column >= 0 and new_column < ncolumns and \\\n",
    "                   in_raster_data[new_row][new_column] != -9999:\n",
    "                    totalpop += in_raster_data[new_row][new_column]\n",
    "                    totalarea += cell_area\n",
    "\n",
    "            if totalarea != 0:\n",
    "                density = float(totalpop)/totalarea\n",
    "                if density > 193:\n",
    "                    suitable = False\n",
    "                    break_flag = True\n",
    "                elif density < 30:\n",
    "                    break_flag = True\n",
    "            else:\n",
    "                suitable = False\n",
    "                break_flag = True\n",
    "    return suitable\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def check_unsuitable_cells(unsuitable_cells, threshold):\n",
    "    unsuitable_shapes = List()\n",
    "    while len(unsuitable_cells) > 0:\n",
    "        start_cell = unsuitable_cells.pop()\n",
    "        to_check = [start_cell]\n",
    "        this_shape = [start_cell]\n",
    "\n",
    "        while len(to_check) > 0:\n",
    "            cell = to_check.pop()\n",
    "            for i, j in [(0, -1), (0, 1), (-1, 0), (1, 0)]:\n",
    "                if (cell[0]+i, cell[1]+j) in unsuitable_cells:\n",
    "                    to_check.append((cell[0]+i, cell[1]+j))\n",
    "                    this_shape.append((cell[0]+i, cell[1]+j))\n",
    "                    unsuitable_cells.remove((cell[0]+i, cell[1]+j))\n",
    "\n",
    "        if len(this_shape) > threshold:\n",
    "            unsuitable_shapes.extend(this_shape)\n",
    "            \n",
    "    return unsuitable_cells, unsuitable_shapes\n",
    "\n",
    "\n",
    "def main(input_raster, out_dir, scenario, year=2100, buffer_km=40):\n",
    " \n",
    "    buffer_relative = create_buffer(buffer_km)        #25 mile (40 km) buffer\n",
    "    buffer_relative.reverse()                   #Look at biggest buffers first\n",
    "\n",
    "    unbuffered_file = os.path.join(out_dir, f\"cerf_densely_populated_{scenario}_{year}.asc\")\n",
    "    buffered_file = os.path.join(out_dir, f\"cerf_densely_populated_{scenario}_{year}_buff25mi.asc\")\n",
    "    nuclear_file = os.path.join(out_dir, f\"cerf_densely_populated_{scenario}_{year}_nuclear.asc\")\n",
    "\n",
    "    headers = []\n",
    "    in_raster_data = []\n",
    "    unsuitable_cells = List()\n",
    "    unsuitable_shapes = List()\n",
    "    buffered_shapes = List()\n",
    "\n",
    "    print('Loading input raster\\n')\n",
    "    inf = open(input_raster,'r')\n",
    "    currentline = inf.readline()\n",
    "\n",
    "    nodata_val = '-999'\n",
    "\n",
    "    while currentline.split()[0] != nodata_val:\n",
    "        headers.append(currentline)\n",
    "        currentline = inf.readline()\n",
    "    while currentline:\n",
    "        in_raster_data.append([int(x) for x in currentline.split()])\n",
    "        currentline = inf.readline()\n",
    "    inf.close()\n",
    "\n",
    "    print( 'Producing unbuffered file\\n')\n",
    "    #produce unbuffered file\n",
    "    f = open(unbuffered_file,'w')\n",
    "    for line in headers:\n",
    "        f.write(line)\n",
    "        \n",
    "    for rowi in range(len(in_raster_data)):\n",
    "        for columni in range(len(in_raster_data[rowi])):\n",
    "            cell = in_raster_data[rowi][columni]\n",
    "            threshold = 772\n",
    "                \n",
    "            if cell > threshold:\n",
    "                f.write('1 ')\n",
    "                unsuitable_cells.append((rowi,columni))\n",
    "                \n",
    "            elif cell == -9999:\n",
    "                f.write('1 ')\n",
    "            else:\n",
    "                f.write('0 ')\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "    print( 'Producing buffered file\\n')\n",
    "    print( '...identifying unsuitable blocks')\n",
    "    threshold = 64.75\n",
    "    \n",
    "    unsuitable_cells, unsuitable_shapes = check_unsuitable_cells(unsuitable_cells, \n",
    "                                                                 threshold)\n",
    "\n",
    "    print( '...buffering')\n",
    "    buffered_shapes = set(buffered_shapes)\n",
    "    \n",
    "    for cell in unsuitable_shapes:\n",
    "        \n",
    "        for offset in buffer_relative:\n",
    "            buffered_shapes.add((cell[0]+offset[0], cell[1]+offset[1]))\n",
    "\n",
    "\n",
    "    print( '...printing result\\n')\n",
    "    with open(buffered_file,'w') as f:\n",
    "        for line in headers:\n",
    "            f.write(line)\n",
    "        for rowi in range(len(in_raster_data)):\n",
    "            for columni in range(len(in_raster_data[rowi])):\n",
    "                if (rowi,columni) in buffered_shapes:\n",
    "                    f.write('1 ')\n",
    "                elif in_raster_data[rowi][columni] == -9999:\n",
    "                    f.write('1 ')\n",
    "                else:\n",
    "                    f.write('0 ')\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print('Producing nuclear file...')\n",
    "    buffer_relative=[]\n",
    "    for i in range(40+1):\n",
    "        buffer_relative.append(create_buffer(i))\n",
    "    cell_area = 1\n",
    "        \n",
    "    nrows = len(in_raster_data)\n",
    "    ncolumns = len(in_raster_data[0])\n",
    "    \n",
    "    return nuclear_file, headers, nrows, ncolumns, buffer_relative, in_raster_data\n",
    "    \n",
    "#     with open(nuclear_file,'w') as f:\n",
    "#         for line in headers:\n",
    "#             f.write(line)\n",
    "\n",
    "#         # for each grid cell row[0], col[0] ... n\n",
    "#         for rowi, columni in itertools.product(range(nrows), range(ncolumns)):\n",
    "\n",
    "#             suitable = True\n",
    "#             break_flag = False\n",
    "\n",
    "#             for radius in buffer_relative:\n",
    "#                 if not break_flag:\n",
    "#                     totalpop = 0\n",
    "#                     totalarea = 0\n",
    "\n",
    "#                     for offset in radius:\n",
    "#                         new_row = rowi + offset[0]\n",
    "#                         new_column = columni + offset[1]\n",
    "\n",
    "#                         if new_row >= 0 and new_row < nrows and new_column >= 0 and new_column < ncolumns and \\\n",
    "#                            in_raster_data[new_row][new_column] != -9999:\n",
    "#                             totalpop += in_raster_data[new_row][new_column]\n",
    "#                             totalarea += cell_area\n",
    "\n",
    "#                     if totalarea != 0:\n",
    "#                         density = float(totalpop)/totalarea\n",
    "\n",
    "#                         if density > 193:\n",
    "#                             suitable = False\n",
    "#                             break_flag = True\n",
    "#                         elif density < 30:\n",
    "#                             break_flag = True\n",
    "#                     else:\n",
    "#                         suitable = False\n",
    "#                         break_flag = True\n",
    "#             if suitable:\n",
    "#                 f.write('0 ')\n",
    "#             else:\n",
    "#                 f.write('1 ')\n",
    "#         f.write('\\n')\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0bc153f-4479-4d62-b8c7-c441e5498d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata = -999\n",
    "\n",
    "with rasterio.open(f) as src:\n",
    "\n",
    "    arr = src.read(1)\n",
    "\n",
    "    arr = np.where(arr == src.nodata, nodata, arr)\n",
    "\n",
    "    # round up to whole numbers\n",
    "    arr = np.around(arr, 0).astype(np.int64)\n",
    "\n",
    "    arr_to_ascii(arr, f_asc, xll=src.bounds.left, yll=src.bounds.bottom, cellsize=1000, nodata=nodata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ba6886-12fd-49fc-9878-477d8bd91a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f511da52-426b-4c24-833f-d937e4791e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading input raster\n",
      "\n",
      "Producing unbuffered file\n",
      "\n",
      "Producing buffered file\n",
      "\n",
      "...identifying unsuitable blocks\n",
      "...buffering\n",
      "...printing result\n",
      "\n",
      "Producing nuclear file...\n",
      "CPU times: user 1min 54s, sys: 951 ms, total: 1min 55s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "outcome = main(f_asc, \n",
    "     out_dir=os.path.dirname(f_asc), \n",
    "     scenario=\"ssp2\", \n",
    "     year=2020)\n",
    "\n",
    "\n",
    "nuclear_file, headers, nrows, ncolumns, buffer_relative, in_raster_data = outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "918918f0-ad20-4440-a071-61630658e5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/d3y010/projects/population/data/cerf_densely_populated_ssp2_2020_nuclear.asc'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuclear_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "517a0105-a87f-4268-95e2-3bdcce7284e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ncols 4815\\n',\n",
       " 'nrows 3104\\n',\n",
       " 'xllcorner -2456207.6475\\n',\n",
       " 'yllcorner -1437505.3457\\n',\n",
       " 'cellsize 1000\\n',\n",
       " 'nodata_value -999\\n']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d6153ee-44d5-480e-ba37-6c083d55ae18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3104, 4815)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows, ncolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93cc616a-54e4-4607-85c0-a3e5bb04d2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buffer_relative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a88e188-5906-4efb-990b-a4f4a9d6e20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3104"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_raster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2907b6c7-1bdf-487c-88fd-c81d7f3a5321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4815"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_raster_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990e67d-e6d1-4c4a-9315-4cb6006fe2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b5802c-961f-46e8-8f9b-6cf990332db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f801b165-073e-4b8b-97b3-45b0aeaefc5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cell_area' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_row \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m new_row \u001b[38;5;241m<\u001b[39m nrows \u001b[38;5;129;01mand\u001b[39;00m new_column \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m new_column \u001b[38;5;241m<\u001b[39m ncolumns \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m     21\u001b[0m        in_raster_data[new_row][new_column] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9999\u001b[39m:\n\u001b[1;32m     22\u001b[0m         totalpop \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m in_raster_data[new_row][new_column]\n\u001b[0;32m---> 23\u001b[0m         totalarea \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcell_area\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m totalarea \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     26\u001b[0m     density \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(totalpop)\u001b[38;5;241m/\u001b[39mtotalarea\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cell_area' is not defined"
     ]
    }
   ],
   "source": [
    "with open(nuclear_file,'w') as f:\n",
    "    for line in headers:\n",
    "        f.write(line)\n",
    "        \n",
    "    # for each grid cell row[0], col[0] ... n\n",
    "    for rowi, columni in itertools.product(range(nrows), range(ncolumns)):\n",
    "\n",
    "        suitable = True\n",
    "        break_flag = False\n",
    "\n",
    "        for radius in buffer_relative:\n",
    "            if not break_flag:\n",
    "                totalpop = 0\n",
    "                totalarea = 0\n",
    "\n",
    "                for offset in radius:\n",
    "                    new_row = rowi + offset[0]\n",
    "                    new_column = columni + offset[1]\n",
    "\n",
    "                    if new_row >= 0 and new_row < nrows and new_column >= 0 and new_column < ncolumns and \\\n",
    "                       in_raster_data[new_row][new_column] != -9999:\n",
    "                        totalpop += in_raster_data[new_row][new_column]\n",
    "                        totalarea += cell_area\n",
    "\n",
    "                if totalarea != 0:\n",
    "                    density = float(totalpop)/totalarea\n",
    "\n",
    "                    if density > 193:\n",
    "                        suitable = False\n",
    "                        break_flag = True\n",
    "                    elif density < 30:\n",
    "                        break_flag = True\n",
    "                else:\n",
    "                    suitable = False\n",
    "                    break_flag = True\n",
    "        if suitable:\n",
    "            f.write('0 ')\n",
    "        else:\n",
    "            f.write('1 ')\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529be7aa-fbaf-48bd-9df6-6a3ca065c28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22456fd9-a433-430c-9d70-86f5e283025a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d802f-4fbf-48ca-bb6f-ab90903c2cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3badafe-0b63-4351-9779-2ef32ede1332",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b18baf-0107-4ae4-9dcf-437455cadfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parent directory path to where this notebook is currently stored\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# data directory in repository\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "# GRIDCERF data directory from downloaded archive\n",
    "gridcerf_dir = os.path.join(data_dir, \"gridcerf\")\n",
    "\n",
    "# GRIDCERF reference data directory\n",
    "reference_dir = os.path.join(gridcerf_dir, \"reference\")\n",
    "\n",
    "# GRIDCERF common data directory\n",
    "common_dir = os.path.join(gridcerf_dir, \"common\")\n",
    "\n",
    "# GRIDCERF technology_specific data directory\n",
    "technology_specific_dir = os.path.join(gridcerf_dir, \"technology_specific\")\n",
    "\n",
    "# GRIDCERF compiled final suitability data directory\n",
    "compiled_dir = os.path.join(gridcerf_dir, \"compiled\")\n",
    "\n",
    "# template land mask raster\n",
    "template_raster = os.path.join(reference_dir, \"gridcerf_landmask.tif\")\n",
    "\n",
    "# source data directory\n",
    "source_dir = os.path.join(gridcerf_dir, \"source\", \"water\")\n",
    "\n",
    "# temporary output raster for processing\n",
    "temp_output_raster = os.path.join(source_dir, \"temporary_raster.tif\")\n",
    "\n",
    "# generate a list of all common exclusion files\n",
    "common_raster_list = glob.glob(os.path.join(common_dir, \"*.tif\"))\n",
    "\n",
    "# source NHD shapefile\n",
    "nhd_shapefile = os.path.join(source_dir, \"surface_water_flow_nhdplus_v2_erom_eispc_v2\", \"ez_gis.surface_water_flow_nhdplus_v2_erom_eispc_v2.shp\")\n",
    "\n",
    "# bins for minimum mean annual flow requirements where the key is the target \n",
    "#  file name and the value is the threshold in MGD\n",
    "mgd_list = [2, 10, 25, 35, 40, 55, 70, 75, 95, 110, 120, 135]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13389bd-68ae-44cb-9e21-74782dc0d8d7",
   "metadata": {},
   "source": [
    "## 4. Generate wind suitability rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39670a53-f114-4b21-a0f0-255fd707e802",
   "metadata": {},
   "source": [
    "### 4.1 Functions to build suitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d387499b-6619-4cd0-b4e8-829f494c1c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nhd_data(nhd_shapefile: str,\n",
    "                        template_raster: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Preprocess NHD flowlines to convert to millions gallons per day (MGD) and prepare\n",
    "    a rasterization field.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # get target coordinate reference system from template raster\n",
    "    with rasterio.open(template_raster) as src:\n",
    "        target_crs = src.crs\n",
    "    \n",
    "    # only keep gallons per minute flow and geometry and reproject\n",
    "    gdf = gpd.read_file(nhd_shapefile)[['q_gpm', 'geometry']].to_crs(target_crs)\n",
    "\n",
    "    # convert to millions gallons per day\n",
    "    gdf['mgd'] = (gdf['q_gpm'] / 1000000) * 60 * 24\n",
    "\n",
    "    # drop gpm field\n",
    "    gdf.drop(columns=['q_gpm'], inplace=True)\n",
    "\n",
    "    # set raster value\n",
    "    gdf['value'] = 0\n",
    "    \n",
    "    return gdf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc3f8ec-5155-44d1-a223-d617042d76c3",
   "metadata": {},
   "source": [
    "### 4.2 Generate available water suitability rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab3684e-8bd0-474d-8f0b-92bcf477f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing NHD data...\n",
      "Processing flow threshold of:  2 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  10 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  25 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  35 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  40 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  55 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  70 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  75 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  95 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  110 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  120 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing flow threshold of:  135 MGD\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "# preprocess NHD flowlines for rasterization to MGD thresholds\n",
    "print(\"Preprocessing NHD data...\")\n",
    "gdf = preprocess_nhd_data(nhd_shapefile=nhd_shapefile,\n",
    "                          template_raster=template_raster)\n",
    "\n",
    "# create buffered flowlines matching the flow requirement\n",
    "for i in mgd_list:\n",
    "    \n",
    "    print(f\"Processing flow threshold of:  {i} MGD\")\n",
    "    \n",
    "    # construct a file basename\n",
    "    basename = f\"gridcerf_nhd2plus_surfaceflow_greaterthan{i}mgd_buffer20km\"\n",
    "    \n",
    "    # extract the flowlines that support the minimum flow requirement\n",
    "    gdx = gdf.loc[gdf['mgd'] >= i].copy()\n",
    "\n",
    "    # buffer by 20 km (20000 meters)\n",
    "    gdx['geometry'] = gdx.buffer(20000)\n",
    "    \n",
    "    # construct temporary shapefile output file path\n",
    "    output_shp = os.path.join(source_dir, f\"{basename}.shp\")\n",
    "    \n",
    "    # write output shapefile\n",
    "    gdx[['value', 'geometry']].to_file(output_shp)\n",
    "    \n",
    "    # construct the water availability raster output raster name\n",
    "    output_raster = os.path.join(technology_specific_dir, f\"{basename}.tif\")\n",
    "\n",
    "    # construct the GDAL raster command\n",
    "    gdal_rasterize_cmd = f\"gdal_rasterize -l {basename} -a value -tr 1000.0 1000.0 -init 1.0 -te -2405552.8355 -1389065.2005 2287447.1645 1609934.7995 -ot Int16 -of GTiff {output_shp} {output_raster}\"\n",
    "    \n",
    "    # execute the GDAL command via the system terminal\n",
    "    os.system(gdal_rasterize_cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a825649-6b1a-4915-8334-e450ad862d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11.2_geo",
   "language": "python",
   "name": "py3.11.2_geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
