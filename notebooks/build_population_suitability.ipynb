{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6a42da-2bd0-4553-84a7-23968b051bb6",
   "metadata": {},
   "source": [
    "# Building population density suitablity layers for GRIDCERF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98f900-a29c-476b-97a9-52d6c105e2a4",
   "metadata": {},
   "source": [
    "## 1. Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f8fea-93e6-4b84-83c4-5868f236fee4",
   "metadata": {},
   "source": [
    "### 1.1 Download GRIDCERF\n",
    "\n",
    "Download the GRIDCERF package if you have not yet done so from here:  https://doi.org/10.5281/zenodo.6601789.  Please extract GRIDCERF inside the `data` directory of this repository as the paths in this notebook are set to that expectation.\n",
    "\n",
    "GRIDCERF provides mosaicked CONUS-scale population rasters for 5-year intervals from 2020 through 2100 for three Shared Socioeconomic Pathways (SSPs):  SSP2, SSP3, and SSP5.  The following is the metadata for the source data:\n",
    "\n",
    "- **Title**:  Data Supplement: U.S. state-level projections of the spatial distribution of population consistent with Shared Socioeconomic Pathways.\n",
    "- **Description from Source**: Â  U.S. state-level projections of the spatial distribution of population consistent with Shared Socioeconomic Pathways.\n",
    "- **Source URL**:  https://doi.org/10.5281/zenodo.3756179\n",
    "- **Date Accessed**:  11/3/21\n",
    "- **Citation**\n",
    "> Zoraghein, H., & O'Neill, B. (2020). Data Supplement: U.S. state-level projections of the spatial distribution of population consistent with Shared Socioeconomic Pathways. (v0.1.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.3756179\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea70c1e0-ea87-4494-9996-b7367c2707e8",
   "metadata": {},
   "source": [
    "## 2. Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221e84b-9735-4916-993a-b9e33afabf39",
   "metadata": {},
   "source": [
    "### 2.1 Import necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51656ba6-795a-4b2f-9af4-3cf5c3596c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a95257-0e31-4ef6-80ae-7761a886556f",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2474e928-d112-4a51-8702-53078a0b31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parent directory path to where this notebook is currently stored\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# data directory in repository\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "# GRIDCERF data directory from downloaded archive\n",
    "gridcerf_dir = os.path.join(data_dir, \"gridcerf\")\n",
    "\n",
    "# GRIDCERF reference data directory\n",
    "reference_dir = os.path.join(gridcerf_dir, \"reference\")\n",
    "\n",
    "# GRIDCERF technology specific source data directory\n",
    "source_dir = os.path.join(gridcerf_dir, \"source\", \"technology_specific\", \"population\")\n",
    "\n",
    "# GRIDCERF technology_specific data directory\n",
    "technology_specific_dir = os.path.join(gridcerf_dir, \"technology_specific\")\n",
    "\n",
    "# GRIDCERF compiled final suitability data directory\n",
    "compiled_dir = os.path.join(gridcerf_dir, \"compiled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6235254f-ffbd-4827-bcdc-7fb8fa5a1269",
   "metadata": {},
   "source": [
    "## 4. Generate population rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29294e2d-18fe-4645-abfd-833480012e76",
   "metadata": {},
   "source": [
    "### 4.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3c2b4f-a3df-4de7-9b21-8b8384459de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_ascii(arr, r_ascii, xll=-180, yll=-90, cellsize=0.25, nodata=-999):\n",
    "    \"\"\"\n",
    "    Convert a numpy array to an ASCII raster.\n",
    "    :@param arr:            2D array\n",
    "    :@param r_ascii:        Full path to outfile with extension\n",
    "    :@param xll:            Longitude coordinate for lower left corner\n",
    "    :@param yll:            Latitude coordinate for lower left corner\n",
    "    :@param cellsize:       Cell size in geographic degrees\n",
    "    :@param nodata:         Value representing NODATA\n",
    "    \"\"\"\n",
    "\n",
    "    # get number of rows and columns of array\n",
    "    nrows = arr.shape[0]\n",
    "    ncols = arr.shape[1]\n",
    "\n",
    "    # create ASCII raster file\n",
    "    with open(r_ascii, 'w') as rast:\n",
    "\n",
    "        # write header\n",
    "        rast.write('ncols {}\\n'.format(ncols))\n",
    "        rast.write('nrows {}\\n'.format(nrows))\n",
    "        rast.write('xllcorner {}\\n'.format(xll))\n",
    "        rast.write('yllcorner {}\\n'.format(yll))\n",
    "        rast.write('cellsize {}\\n'.format(cellsize))\n",
    "        rast.write('nodata_value {}\\n'.format(nodata))\n",
    "\n",
    "        # write array\n",
    "        np.savetxt(rast, arr, fmt='%.15g')\n",
    "        \n",
    "\n",
    "\n",
    "def create_buffer(radius):  #radius given in #cells\n",
    "    \n",
    "    b = []\n",
    "    for i in range(radius+1):\n",
    "        \n",
    "        for j in range(radius+1):\n",
    "            \n",
    "            if math.sqrt(i**2 + j**2) <= radius:\n",
    "                \n",
    "                if i==0 and j==0:\n",
    "                    b.extend([(i,j)])\n",
    "                elif i==0:\n",
    "                    b.extend([(i,j),(i,-j)])\n",
    "                elif j==0:\n",
    "                    b.extend([(i,j),(-i,j)])\n",
    "                else:\n",
    "                    b.extend([(i,j),(-i,j),(i,-j),(-i,-j)])\n",
    "                    \n",
    "    return b\n",
    "\n",
    "\n",
    "def geotiff_to_ascii(geotiff_path, ascii_path, nodata=-999):\n",
    "    \n",
    "    with rasterio.open(geotiff_path) as src:\n",
    "        array = src.read(1)\n",
    "        with open(ascii_path, 'w') as f:\n",
    "            f.write('ncols         {}\\n'.format(array.shape[1]))\n",
    "            f.write('nrows         {}\\n'.format(array.shape[0]))\n",
    "            f.write('xllcorner     {}\\n'.format(src.bounds[0]))\n",
    "            f.write('yllcorner     {}\\n'.format(src.bounds[1]))\n",
    "            f.write('cellsize      {}\\n'.format(src.res[0]))\n",
    "            f.write(f'NODATA_value  {nodata}\\n')\n",
    "            for row in array:\n",
    "                for value in row:\n",
    "                    f.write(' ' + str(value))\n",
    "                f.write('\\n')\n",
    "\n",
    "\n",
    "def check_unsuitable_cells(unsuitable_cells, unsuitable_shapes, threshold):\n",
    "    while len(unsuitable_cells) > 0:\n",
    "        start_cell = unsuitable_cells.pop()\n",
    "        to_check = [start_cell]\n",
    "        this_shape = [start_cell]\n",
    "\n",
    "        while len(to_check) > 0:\n",
    "            cell = to_check.pop()\n",
    "            for i, j in [(0, -1), (0, 1), (-1, 0), (1, 0)]:\n",
    "                if (cell[0]+i, cell[1]+j) in unsuitable_cells:\n",
    "                    to_check.append((cell[0]+i, cell[1]+j))\n",
    "                    this_shape.append((cell[0]+i, cell[1]+j))\n",
    "                    unsuitable_cells.remove((cell[0]+i, cell[1]+j))\n",
    "\n",
    "        if len(this_shape) > threshold:\n",
    "            unsuitable_shapes.extend(this_shape)\n",
    "            \n",
    "    return unsuitable_cells, unsuitable_shapes\n",
    "\n",
    "\n",
    "def main(input_raster, out_dir, scenario, year=2100, buffer_km=40):\n",
    " \n",
    "    buffer_relative = create_buffer(buffer_km)        #25 mile (40 km) buffer\n",
    "    buffer_relative.reverse()                   #Look at biggest buffers first\n",
    "\n",
    "    unbuffered_file = os.path.join(out_dir, f\"gridcerf_densely_populated_{scenario}_{year}.asc\")\n",
    "    buffered_file = os.path.join(out_dir, f\"gridcerf_densely_populated_{scenario}_{year}_buff25mi.asc\")\n",
    "    nuclear_file = os.path.join(out_dir, f\"gridcerf_densely_populated_{scenario}_{year}_nuclear.asc\")\n",
    "\n",
    "    headers = []\n",
    "    in_raster_data = []\n",
    "    unsuitable_cells = []\n",
    "    unsuitable_shapes = []\n",
    "    buffered_shapes = []\n",
    "\n",
    "    print('Loading input raster\\n')\n",
    "    inf = open(input_raster,'r')\n",
    "    currentline = inf.readline()\n",
    "\n",
    "    nodata_val = '-999'\n",
    "\n",
    "    while currentline.split()[0] != nodata_val:\n",
    "        headers.append(currentline)\n",
    "        currentline = inf.readline()\n",
    "    while currentline:\n",
    "        in_raster_data.append([int(x) for x in currentline.split()])\n",
    "        currentline = inf.readline()\n",
    "    inf.close()\n",
    "\n",
    "    print( 'Producing unbuffered file\\n')\n",
    "    #produce unbuffered file\n",
    "    f = open(unbuffered_file,'w')\n",
    "    for line in headers:\n",
    "        f.write(line)\n",
    "        \n",
    "    for rowi in range(len(in_raster_data)):\n",
    "        for columni in range(len(in_raster_data[rowi])):\n",
    "            cell = in_raster_data[rowi][columni]\n",
    "            threshold = 772\n",
    "                \n",
    "            if cell > threshold:\n",
    "                f.write('1 ')\n",
    "                unsuitable_cells.append((rowi,columni))\n",
    "                \n",
    "            elif cell == -9999:\n",
    "                f.write('1 ')\n",
    "            else:\n",
    "                f.write('0 ')\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "    print( 'Producing buffered file\\n')\n",
    "    print( '...identifying unsuitable blocks')\n",
    "            \n",
    "    threshold = 64.75\n",
    "\n",
    "    while len(unsuitable_cells) > 0:\n",
    "        start_cell = unsuitable_cells.pop()\n",
    "        to_check = [start_cell]\n",
    "        this_shape = [start_cell]\n",
    "        \n",
    "        while len(to_check) > 0:\n",
    "            cell = to_check.pop()\n",
    "            if (cell[0],cell[1]-1) in unsuitable_cells:\n",
    "                to_check.append((cell[0],cell[1]-1))\n",
    "                this_shape.append((cell[0],cell[1]-1))\n",
    "                unsuitable_cells.remove((cell[0],cell[1]-1))\n",
    "            if (cell[0],cell[1]+1) in unsuitable_cells:\n",
    "                to_check.append((cell[0],cell[1]+1))\n",
    "                this_shape.append((cell[0],cell[1]+1))\n",
    "                unsuitable_cells.remove((cell[0],cell[1]+1))\n",
    "            if (cell[0]-1,cell[1]) in unsuitable_cells:\n",
    "                to_check.append((cell[0]-1,cell[1]))\n",
    "                this_shape.append((cell[0]-1,cell[1]))\n",
    "                unsuitable_cells.remove((cell[0]-1,cell[1]))\n",
    "            if (cell[0]+1,cell[1]) in unsuitable_cells:\n",
    "                to_check.append((cell[0]+1,cell[1]))\n",
    "                this_shape.append((cell[0]+1,cell[1]))\n",
    "                unsuitable_cells.remove((cell[0]+1,cell[1]))\n",
    "                \n",
    "        if len(this_shape) > threshold:\n",
    "            unsuitable_shapes.extend(this_shape)\n",
    "            \n",
    "    unsuitable_cells = this_shape = None     #free up memory\n",
    "\n",
    "    print( '...buffering')\n",
    "    buffered_shapes = set(buffered_shapes)\n",
    "    \n",
    "    for cell in unsuitable_shapes:\n",
    "        \n",
    "        for offset in buffer_relative:\n",
    "            buffered_shapes.add((cell[0]+offset[0], cell[1]+offset[1]))\n",
    "\n",
    "\n",
    "    print( '...printing result\\n')\n",
    "    with open(buffered_file,'w') as f:\n",
    "        for line in headers:\n",
    "            f.write(line)\n",
    "        for rowi in range(len(in_raster_data)):\n",
    "            for columni in range(len(in_raster_data[rowi])):\n",
    "                if (rowi,columni) in buffered_shapes:\n",
    "                    f.write('1 ')\n",
    "                elif in_raster_data[rowi][columni] == -9999:\n",
    "                    f.write('1 ')\n",
    "                else:\n",
    "                    f.write('0 ')\n",
    "            f.write('\\n')\n",
    "    \n",
    "\n",
    "    print('Producing nuclear file...')\n",
    "    buffer_relative=[]\n",
    "    for i in range(40+1):\n",
    "        buffer_relative.append(create_buffer(i))\n",
    "    cell_area = 1\n",
    "        \n",
    "    nrows = len(in_raster_data)\n",
    "    ncolumns = len(in_raster_data[0])\n",
    "    \n",
    "    f = open(nuclear_file,'w')\n",
    "    for line in headers:\n",
    "        f.write(line)\n",
    "    for rowi in range(nrows):\n",
    "\n",
    "        for columni in range(ncolumns):\n",
    "            suitable = True\n",
    "            break_flag = False\n",
    "            for radius in buffer_relative:\n",
    "                if not break_flag:\n",
    "                    totalpop = 0\n",
    "                    totalarea = 0\n",
    "\n",
    "                    for offset in radius:\n",
    "                        new_row = rowi + offset[0]\n",
    "                        new_column = columni + offset[1]\n",
    "                        if new_row >= 0 and new_row < nrows and new_column >= 0 and new_column < ncolumns and \\\n",
    "                           in_raster_data[new_row][new_column] != -9999:\n",
    "                            totalpop += in_raster_data[new_row][new_column]\n",
    "                            totalarea += cell_area\n",
    "\n",
    "                    if totalarea != 0:\n",
    "                        density = float(totalpop)/totalarea\n",
    "                        if density > 193:\n",
    "                            suitable = False\n",
    "                            break_flag = True\n",
    "                        elif density < 30:\n",
    "                            break_flag = True\n",
    "                    else:\n",
    "                        suitable = False\n",
    "                        break_flag = True\n",
    "            if suitable:\n",
    "                f.write('0 ')\n",
    "            else:\n",
    "                f.write('1 ')\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af62f3e-1682-49be-a58d-364654dfe732",
   "metadata": {},
   "source": [
    "### 4.2 This code generates the population files on a year by year basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9320ef95-86dc-4297-a923-6e5965d7578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target SSP\n",
    "ssp = \"ssp2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae9f8a42-aac5-4999-98fc-846b9210327c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2050_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2100_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2020_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2030_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2040_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2060_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2090_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2080_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2070_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2085_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2075_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2065_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2095_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2035_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2045_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2055_1km_conus.tif',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2025_1km_conus.tif']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of population files for a specific SSP for all years\n",
    "raster_files = glob.glob(os.path.join(source_dir, f\"gridcerf_population_{ssp}_*_1km_conus.tif\"))\n",
    "\n",
    "raster_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d2230c-6f50-4319-8df6-d9c2c671c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the files to ASC rasters\n",
    "for i in raster_files:\n",
    "    geotiff_to_ascii(i, f\"{os.path.splitext(i)[0]}.asc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f3a9c0-2a85-409d-ae61-3ebfecd8654e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2040_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2030_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2020_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2050_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2100_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2070_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2080_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2090_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2060_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2095_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2065_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2075_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2085_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2025_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2055_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2045_1km_conus.asc',\n",
       " '/Users/d3y010/repos/metarepos/vernon-etal_2022_scidata/data/gridcerf/source/technology_specific/population/gridcerf_population_ssp2_2035_1km_conus.asc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of population ascii for a specific SSP for all years\n",
    "ascii_files = glob.glob(os.path.join(source_dir, f\"gridcerf_population_{ssp}_*_1km_conus.asc\"))\n",
    "\n",
    "ascii_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6411e6fc-38cc-412f-9e38-6559a4fa1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# get a file to process; could process all in loop\n",
    "f_asc = ascii_files[0]\n",
    "\n",
    "# strip year from file\n",
    "yr = int(os.path.basename(f_asc).split(\"_\")[3])\n",
    "\n",
    "# process file\n",
    "outcome = main(f_asc, \n",
    "                 out_dir=os.path.dirname(f_asc), \n",
    "                 scenario=ssp, \n",
    "                 year=2020)\n",
    "\n",
    "\n",
    "nuclear_file, headers, nrows, ncolumns, buffer_relative, in_raster_data = outcome\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11.2_geo",
   "language": "python",
   "name": "py3.11.2_geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
